







.version 7.0
.target sm_80
.address_size 64



.func _Z9C_tile_wb7StgFragPfPKfjjjjj(
.param .align 4 .b8 _Z9C_tile_wb7StgFragPfPKfjjjjj_param_0[64],
.param .b64 _Z9C_tile_wb7StgFragPfPKfjjjjj_param_1,
.param .b64 _Z9C_tile_wb7StgFragPfPKfjjjjj_param_2,
.param .b32 _Z9C_tile_wb7StgFragPfPKfjjjjj_param_3,
.param .b32 _Z9C_tile_wb7StgFragPfPKfjjjjj_param_4,
.param .b32 _Z9C_tile_wb7StgFragPfPKfjjjjj_param_5,
.param .b32 _Z9C_tile_wb7StgFragPfPKfjjjjj_param_6,
.param .b32 _Z9C_tile_wb7StgFragPfPKfjjjjj_param_7
)
{
.local .align 4 .b8 __local_depot0[64];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<13>;
.reg .f32 %f<22>;
.reg .b32 %r<23>;
.reg .b64 %rd<27>;


mov.u64 %SPL, __local_depot0;
cvta.local.u64 %SP, %SPL;
ld.param.f32 %f2, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+4];
ld.param.f32 %f3, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+8];
ld.param.f32 %f4, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+12];
ld.param.f32 %f5, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+16];
ld.param.f32 %f6, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+20];
ld.param.f32 %f7, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+24];
ld.param.f32 %f8, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+28];
ld.param.f32 %f9, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+32];
ld.param.f32 %f10, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+36];
ld.param.f32 %f11, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+40];
ld.param.f32 %f12, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+44];
ld.param.f32 %f13, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+48];
ld.param.f32 %f14, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+52];
ld.param.f32 %f15, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+56];
ld.param.f32 %f16, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0+60];
ld.param.u64 %rd3, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_1];
ld.param.u64 %rd4, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_2];
ld.param.u32 %r7, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_3];
ld.param.u32 %r8, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_4];
ld.param.u32 %r9, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_5];
ld.param.u32 %r10, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_6];
ld.param.u32 %r11, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_7];
ld.param.f32 %f1, [_Z9C_tile_wb7StgFragPfPKfjjjjj_param_0];
st.f32 [%SP+60], %f16;
st.f32 [%SP+56], %f15;
st.f32 [%SP+52], %f14;
st.f32 [%SP+48], %f13;
st.f32 [%SP+44], %f12;
st.f32 [%SP+40], %f11;
st.f32 [%SP+36], %f10;
st.f32 [%SP+32], %f9;
st.f32 [%SP+28], %f8;
st.f32 [%SP+24], %f7;
st.f32 [%SP+20], %f6;
st.f32 [%SP+16], %f5;
st.f32 [%SP+12], %f4;
st.f32 [%SP+8], %f3;
st.f32 [%SP+4], %f2;
st.f32 [%SP+0], %f1;

bar.sync 0;
mov.u32 %r12, 0;
mov.u32 %r20, %r12;

BB0_2:
mov.u32 %r1, %r20;
setp.lt.s32	%p3, %r1, 4;
not.pred %p4, %p3;
@%p4 bra BB0_5;
bra.uni BB0_3;

BB0_3:
cvt.s64.s32	%rd10, %r1;
shl.b64 %rd11, %rd10, 4;
add.u64 %rd12, %SP, 0;
add.s64 %rd13, %rd12, %rd11;
cvt.s64.s32	%rd14, %r1;
shl.b64 %rd15, %rd14, 4;
add.s64 %rd16, %rd12, %rd15;
cvt.s64.s32	%rd17, %r1;
shl.b64 %rd18, %rd17, 4;
add.s64 %rd19, %rd12, %rd18;
cvt.s64.s32	%rd20, %r1;
shl.b64 %rd21, %rd20, 4;
add.s64 %rd22, %rd12, %rd21;
cvt.u64.u32	%rd23, %r7;
mul.lo.s32 %r19, %r1, 8;
cvt.s64.s32	%rd24, %r19;
mul.lo.s64 %rd25, %rd24, 16;
add.s64 %rd26, %rd23, %rd25;
cvt.u32.u64	%r18, %rd26;
ld.f32 %f18, [%rd13];
ld.f32 %f19, [%rd16+4];
ld.f32 %f20, [%rd19+8];
ld.f32 %f21, [%rd22+12];

	st.shared.v4.f32 [%r18], {%f18, %f19, %f20, %f21};



add.s32 %r2, %r1, 1;
mov.u32 %r20, %r2;
bra.uni BB0_2;

BB0_5:
bar.sync 0;

setp.lt.u32	%p5, %r8, %r10;
not.pred %p6, %p5;
@%p6 bra BB0_8;
bra.uni BB0_7;

BB0_7:
mov.u32 %r13, 0;
mov.u32 %r21, %r13;
bra.uni BB0_9;

BB0_8:
sub.s32 %r3, %r8, %r10;
mov.u32 %r21, %r3;

BB0_9:
mov.u32 %r4, %r21;
mov.u32 %r14, 0;
mov.u32 %r22, %r14;

BB0_10:
mov.u32 %r5, %r22;
setp.lt.s32	%p7, %r5, 16;
not.pred %p8, %p7;
@%p8 bra BB0_15;
bra.uni BB0_11;

BB0_11:
mul.lo.s32 %r15, %r5, 32;
cvt.s64.s32	%rd5, %r15;
shl.b64 %rd6, %rd5, 2;
add.s64 %rd1, %rd4, %rd6;
mul.lo.s32 %r16, %r5, %r9;
cvt.u64.u32	%rd7, %r16;
shl.b64 %rd8, %rd7, 2;
add.s64 %rd2, %rd3, %rd8;
setp.lt.u32	%p10, %r5, %r4;
mov.pred %p9, 0;
not.pred %p11, %p10;
mov.pred %p12, %p9;
@%p11 bra BB0_13;
bra.uni BB0_12;

BB0_12:
setp.lt.u32	%p1, %r11, %r9;
mov.pred %p12, %p1;

BB0_13:
mov.pred %p2, %p12;
ld.f32 %f17, [%rd1];
selp.u32	%r17, 1, 0, %p2;

	{.reg .pred p;
setp.ne.b32 p, %r17, 0;
@p st.global.f32 [%rd2], %f17;}



add.s32 %r6, %r5, 1;
mov.u32 %r22, %r6;
bra.uni BB0_10;

BB0_15:
ret;
}


.visible .entry _Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj(
.param .u64 _Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_0,
.param .u64 _Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_1,
.param .u64 _Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_2,
.param .u32 _Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_3,
.param .u32 _Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_4,
.param .u32 _Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_5,
.param .u32 _Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_6,
.param .u32 _Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_7
)
.maxntid 256, 1, 1
.minnctapersm 2
{
.local .align 4 .b8 __local_depot1[480];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<82>;
.reg .f32 %f<95>;
.reg .b32 %r<421>;
.reg .b64 %rd<372>;

	.shared .align 16384 .b8 _ZZ22sgemm_128x128x8_kernelPKfS0_PfjjjjjE4smem[24576];

mov.u64 %SPL, __local_depot1;
cvta.local.u64 %SP, %SPL;
ld.param.u64 %rd15, [_Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_0];
ld.param.u64 %rd16, [_Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_1];
ld.param.u64 %rd17, [_Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_2];
ld.param.u32 %r90, [_Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_3];
ld.param.u32 %r91, [_Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_4];
ld.param.u32 %r92, [_Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_5];
ld.param.u32 %r93, [_Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_6];
ld.param.u32 %r94, [_Z22sgemm_128x128x8_kernelPKfS0_Pfjjjjj_param_7];
mov.u32 %r95, 0;
mov.u32 %r379, %r95;

BB1_1:
mov.u32 %r1, %r379;
setp.lt.s32	%p5, %r1, 8;
not.pred %p6, %p5;
@%p6 bra BB1_8;
bra.uni BB1_2;

BB1_2:
mov.u32 %r377, 0;
mov.u32 %r380, %r377;

BB1_3:
mov.u32 %r2, %r380;
setp.lt.s32	%p78, %r2, 8;
not.pred %p79, %p78;
@%p79 bra BB1_6;
bra.uni BB1_4;

BB1_4:
cvt.s64.s32	%rd359, %r1;
shl.b64 %rd360, %rd359, 5;
add.u64 %rd361, %SP, 128;
add.s64 %rd362, %rd361, %rd360;
cvt.s64.s32	%rd363, %r2;
shl.b64 %rd364, %rd363, 2;
add.s64 %rd365, %rd362, %rd364;
mov.u32 %r378, 0;
st.u32 [%rd365], %r378;

add.s32 %r3, %r2, 1;
mov.u32 %r380, %r3;
bra.uni BB1_3;

BB1_6:

add.s32 %r4, %r1, 1;
mov.u32 %r379, %r4;
bra.uni BB1_1;

BB1_8:
mov.u32 %r102, %tid.x;
rem.u32 %r5, %r102, 32;
mov.u32 %r103, %tid.x;
div.u32 %r6, %r103, 32;
div.u32 %r104, %r5, 2;
rem.u32 %r7, %r104, 8;
div.u32 %r105, %r5, 16;
mul.lo.s32 %r106, %r105, 2;
rem.u32 %r107, %r5, 2;
add.s32 %r8, %r106, %r107;
mov.u32 %r108, %ctaid.y;
mul.lo.s32 %r109, %r108, 128;
mov.u32 %r110, %tid.x;
div.u32 %r111, %r110, 8;
mul.lo.s32 %r112, %r111, 4;
add.s32 %r113, %r109, %r112;
mul.lo.s32 %r114, %r113, %r92;
cvt.u64.u32	%rd22, %r114;
shl.b64 %rd23, %rd22, 2;
add.s64 %rd24, %rd15, %rd23;
mov.u32 %r115, %tid.x;
rem.u32 %r116, %r115, 8;
cvt.u64.u32	%rd25, %r116;
shl.b64 %rd26, %rd25, 2;
add.s64 %rd1, %rd24, %rd26;
mov.u32 %r117, %tid.x;
div.u32 %r118, %r117, 32;
mul.lo.s32 %r119, %r118, %r91;
cvt.u64.u32	%rd27, %r119;
shl.b64 %rd28, %rd27, 2;
add.s64 %rd29, %rd16, %rd28;
mov.u32 %r120, %ctaid.x;
mul.lo.s32 %r121, %r120, 128;
cvt.u64.u32	%rd30, %r121;
shl.b64 %rd31, %rd30, 2;
add.s64 %rd32, %rd29, %rd31;
mov.u32 %r122, %tid.x;
rem.u32 %r123, %r122, 32;
cvt.u64.u32	%rd33, %r123;
shl.b64 %rd34, %rd33, 2;
add.s64 %rd2, %rd32, %rd34;
mov.u32 %r124, %tid.x;
rem.u32 %r125, %r124, 8;
mul.lo.s32 %r126, %r125, 132;
cvt.u64.u32	%rd35, %r126;
mov.u32 %r127, _ZZ22sgemm_128x128x8_kernelPKfS0_PfjjjjjE4smem;
{
.reg .u64 %temp; 
cvt.u64.u32 %temp, %r127;
cvta.shared.u64 %rd36, %temp;
}
shl.b64 %rd37, %rd35, 2;
add.s64 %rd38, %rd36, %rd37;
mov.u32 %r128, %tid.x;
div.u32 %r129, %r128, 8;
mul.lo.s32 %r130, %r129, 4;
cvt.u64.u32	%rd39, %r130;
shl.b64 %rd40, %rd39, 2;
add.s64 %rd18, %rd38, %rd40;

	{.reg .u64 u64addr;
cvta.to.shared.u64 u64addr, %rd18;
cvt.u32.u64 %r96, u64addr;}


	mov.u32 %r131, %tid.x;
div.u32 %r132, %r131, 32;
mul.lo.s32 %r133, %r132, 128;
cvt.u64.u32	%rd41, %r133;
{
.reg .u64 %temp; 
cvt.u64.u32 %temp, %r127;
cvta.shared.u64 %rd42, %temp;
}
add.s64 %rd43, %rd42, 16384;
shl.b64 %rd44, %rd41, 2;
add.s64 %rd45, %rd43, %rd44;
mov.u32 %r134, %tid.x;
rem.u32 %r135, %r134, 32;
cvt.u64.u32	%rd46, %r135;
shl.b64 %rd47, %rd46, 2;
add.s64 %rd19, %rd45, %rd47;

	{.reg .u64 u64addr;
cvta.to.shared.u64 u64addr, %rd19;
cvt.u32.u64 %r97, u64addr;}


	div.u32 %r136, %r6, 2;
mul.lo.s32 %r137, %r136, 32;
cvt.u64.u32	%rd48, %r137;
shl.b64 %rd49, %rd48, 2;
add.s64 %rd50, %rd36, %rd49;
mul.lo.s32 %r138, %r8, 4;
cvt.u64.u32	%rd51, %r138;
shl.b64 %rd52, %rd51, 2;
add.s64 %rd20, %rd50, %rd52;

	{.reg .u64 u64addr;
cvta.to.shared.u64 u64addr, %rd20;
cvt.u32.u64 %r98, u64addr;}


	rem.u32 %r139, %r6, 2;
mul.lo.s32 %r140, %r139, 64;
cvt.u64.u32	%rd53, %r140;
shl.b64 %rd54, %rd53, 2;
add.s64 %rd55, %rd43, %rd54;
mul.lo.s32 %r141, %r7, 4;
cvt.u64.u32	%rd56, %r141;
shl.b64 %rd57, %rd56, 2;
add.s64 %rd21, %rd55, %rd57;

	{.reg .u64 u64addr;
cvta.to.shared.u64 u64addr, %rd21;
cvt.u32.u64 %r99, u64addr;}


	mov.u32 %r101, 0;
mov.u32 %r381, %r101;
mov.u32 %r382, %r101;

BB1_9:
mov.u32 %r14, %r382;
mov.u32 %r13, %r381;
setp.lt.s32	%p7, %r14, 4;
not.pred %p8, %p7;
@%p8 bra BB1_14;
bra.uni BB1_10;

BB1_10:
mov.u32 %r368, %ctaid.y;
mul.lo.s32 %r369, %r368, 128;
mov.u32 %r370, %tid.x;
div.u32 %r371, %r370, 8;
mul.lo.s32 %r372, %r371, 4;
add.s32 %r373, %r369, %r372;
add.s32 %r374, %r373, %r14;
setp.lt.u32	%p76, %r374, %r90;
not.pred %p77, %p76;
mov.u32 %r383, %r13;
@%p77 bra BB1_12;
bra.uni BB1_11;

BB1_11:
mov.u32 %r375, 1;
shl.b32 %r376, %r375, %r14;
or.b32 %r15, %r13, %r376;
mov.u32 %r383, %r15;

BB1_12:
mov.u32 %r16, %r383;

add.s32 %r17, %r14, 1;
mov.u32 %r381, %r16;
mov.u32 %r382, %r17;
bra.uni BB1_9;

BB1_14:
mov.u32 %r143, 0;
mov.u32 %r384, %r143;
mov.u32 %r385, %r143;

BB1_15:
mov.u32 %r19, %r385;
mov.u32 %r18, %r384;
setp.lt.s32	%p9, %r19, 4;
not.pred %p10, %p9;
@%p10 bra BB1_20;
bra.uni BB1_16;

BB1_16:
mov.u32 %r359, %ctaid.x;
mul.lo.s32 %r360, %r359, 128;
mov.u32 %r361, %tid.x;
rem.u32 %r362, %r361, 32;
add.s32 %r363, %r360, %r362;
mul.lo.s32 %r364, %r19, 32;
add.s32 %r365, %r363, %r364;
setp.lt.u32	%p74, %r365, %r91;
not.pred %p75, %p74;
mov.u32 %r386, %r18;
@%p75 bra BB1_18;
bra.uni BB1_17;

BB1_17:
mov.u32 %r366, 1;
shl.b32 %r367, %r366, %r19;
or.b32 %r20, %r18, %r367;
mov.u32 %r386, %r20;

BB1_18:
mov.u32 %r21, %r386;

add.s32 %r22, %r19, 1;
mov.u32 %r384, %r21;
mov.u32 %r385, %r22;
bra.uni BB1_15;

BB1_20:
add.s32 %r145, %r92, 7;
div.u32 %r146, %r145, 8;
sub.s32 %r23, %r146, 1;
mul.lo.s32 %r147, %r23, 8;
sub.s32 %r24, %r92, %r147;
mov.u32 %r144, 0;
mov.u32 %r387, %r144;

BB1_21:
mov.u32 %r25, %r387;
setp.lt.s32	%p11, %r25, 4;
not.pred %p12, %p11;
@%p12 bra BB1_26;
bra.uni BB1_22;

BB1_22:
mov.u32 %r352, 1;
shl.b32 %r353, %r352, %r25;
and.b32 %r354, %r13, %r353;
setp.ne.s32	%p72, %r354, 0;
mov.pred %p71, 0;
not.pred %p73, %p72;
mov.pred %p80, %p71;
@%p73 bra BB1_24;
bra.uni BB1_23;

BB1_23:
mov.u32 %r355, %tid.x;
rem.u32 %r356, %r355, 8;
setp.lt.u32	%p1, %r356, %r24;
mov.pred %p80, %p1;

BB1_24:
mov.pred %p2, %p80;
cvt.s64.s32	%rd354, %r25;
shl.b64 %rd355, %rd354, 2;
add.u64 %rd356, %SP, 384;
add.s64 %rd357, %rd356, %rd355;
mul.lo.s32 %r358, %r25, %r93;
cvt.u64.u32	%rd358, %r358;
add.s64 %rd353, %rd1, %rd358;
selp.u32	%r357, 1, 0, %p2;

	{.reg .pred p;
setp.ne.b32 p, %r357, 0;
@!p mov.b32 %f94, 0;
@p ld.global.nc.f32 %f94, [%rd353];}


	st.f32 [%rd357], %f94;

add.s32 %r26, %r25, 1;
mov.u32 %r387, %r26;
bra.uni BB1_21;

BB1_26:
ld.f32 %f1, [%SP+384];
ld.f32 %f2, [%SP+388];
ld.f32 %f3, [%SP+392];
ld.f32 %f4, [%SP+396];

	st.shared.v4.f32 [%r96], {%f1, %f2, %f3, %f4};


	mov.u32 %r149, 0;
mov.u32 %r388, %r149;

BB1_27:
mov.u32 %r27, %r388;
setp.lt.s32	%p13, %r27, 4;
not.pred %p14, %p13;
@%p14 bra BB1_32;
bra.uni BB1_28;

BB1_28:
mov.u32 %r345, 1;
shl.b32 %r346, %r345, %r27;
and.b32 %r347, %r18, %r346;
setp.ne.s32	%p69, %r347, 0;
mov.pred %p68, 0;
not.pred %p70, %p69;
mov.pred %p81, %p68;
@%p70 bra BB1_30;
bra.uni BB1_29;

BB1_29:
mov.u32 %r348, %tid.x;
div.u32 %r349, %r348, 32;
setp.lt.u32	%p3, %r349, %r24;
mov.pred %p81, %p3;

BB1_30:
mov.pred %p4, %p81;
cvt.s64.s32	%rd347, %r27;
shl.b64 %rd348, %rd347, 2;
add.u64 %rd349, %SP, 400;
add.s64 %rd350, %rd349, %rd348;
mul.lo.s32 %r351, %r27, 32;
cvt.s64.s32	%rd351, %r351;
mul.lo.s64 %rd352, %rd351, 4;
add.s64 %rd346, %rd2, %rd352;
selp.u32	%r350, 1, 0, %p4;

	{.reg .pred p;
setp.ne.b32 p, %r350, 0;
@!p mov.b32 %f93, 0;
@p ld.global.nc.f32 %f93, [%rd346];}


	st.f32 [%rd350], %f93;

add.s32 %r28, %r27, 1;
mov.u32 %r388, %r28;
bra.uni BB1_27;

BB1_32:
mov.u32 %r150, 0;
mov.u32 %r389, %r150;

BB1_33:
mov.u32 %r29, %r389;
setp.lt.s32	%p15, %r29, 4;
not.pred %p16, %p15;
@%p16 bra BB1_36;
bra.uni BB1_34;

BB1_34:
cvt.s64.s32	%rd338, %r29;
shl.b64 %rd339, %rd338, 2;
add.u64 %rd340, %SP, 400;
add.s64 %rd341, %rd340, %rd339;
cvt.u64.u32	%rd342, %r97;
mul.lo.s32 %r344, %r29, 32;
cvt.s64.s32	%rd343, %r344;
mul.lo.s64 %rd344, %rd343, 4;
add.s64 %rd345, %rd342, %rd344;
cvt.u32.u64	%r343, %rd345;
ld.f32 %f92, [%rd341];

	st.shared.f32 [%r343], %f92;



add.s32 %r30, %r29, 1;
mov.u32 %r389, %r30;
bra.uni BB1_33;

BB1_36:
bar.sync 0;

xor.b32 %r31, %r96, 8192;
xor.b32 %r32, %r97, 4096;
cvt.u64.u32	%rd58, %r24;
mul.lo.s64 %rd59, %rd58, 4;
add.s64 %rd3, %rd1, %rd59;
mul.lo.s32 %r155, %r91, %r24;
cvt.u64.u32	%rd60, %r155;
mul.lo.s64 %rd61, %rd60, 4;
add.s64 %rd4, %rd2, %rd61;

	ld.shared.v4.f32 {%f5, %f6, %f7, %f8}, [%r98];


	st.f32 [%SP+0], %f5;
st.f32 [%SP+4], %f6;
st.f32 [%SP+8], %f7;
st.f32 [%SP+12], %f8;
cvt.u64.u32	%rd62, %r98;
add.s64 %rd63, %rd62, 64;
cvt.u32.u64	%r152, %rd63;

	ld.shared.v4.f32 {%f9, %f10, %f11, %f12}, [%r152];


	st.f32 [%SP+16], %f9;
st.f32 [%SP+20], %f10;
st.f32 [%SP+24], %f11;
st.f32 [%SP+28], %f12;

	ld.shared.v4.f32 {%f13, %f14, %f15, %f16}, [%r99];


	st.f32 [%SP+64], %f13;
st.f32 [%SP+68], %f14;
st.f32 [%SP+72], %f15;
st.f32 [%SP+76], %f16;
cvt.u64.u32	%rd64, %r99;
add.s64 %rd65, %rd64, 128;
cvt.u32.u64	%r154, %rd65;

	ld.shared.v4.f32 {%f17, %f18, %f19, %f20}, [%r154];


	st.f32 [%SP+80], %f17;
st.f32 [%SP+84], %f18;
st.f32 [%SP+88], %f19;
st.f32 [%SP+92], %f20;
mov.u32 %r390, %r31;
mov.u32 %r391, %r98;
mov.u32 %r392, %r99;
mov.u64 %rd366, %rd3;
mov.u64 %rd367, %rd4;
mov.u32 %r393, %r32;
mov.u32 %r394, %r23;

BB1_38:
mov.u32 %r37, %r394;
mov.u32 %r36, %r393;
mov.u64 %rd6, %rd367;
mov.u64 %rd5, %rd366;
mov.u32 %r35, %r392;
mov.u32 %r34, %r391;
mov.u32 %r33, %r390;
setp.gt.u32	%p17, %r37, 0;
not.pred %p18, %p17;
@%p18 bra BB1_70;
bra.uni BB1_39;

BB1_39:
mov.u32 %r272, 0;
mov.u32 %r395, %r33;
mov.u32 %r396, %r34;
mov.u32 %r397, %r35;
mov.u64 %rd368, %rd5;
mov.u64 %rd369, %rd6;
mov.u32 %r398, %r36;
mov.u32 %r399, %r272;

BB1_40:
mov.u32 %r42, %r399;
mov.u32 %r41, %r398;
mov.u64 %rd8, %rd369;
mov.u64 %rd7, %rd368;
mov.u32 %r40, %r397;
mov.u32 %r39, %r396;
mov.u32 %r38, %r395;
setp.lt.s32	%p50, %r42, 8;
not.pred %p51, %p50;
@%p51 bra BB1_68;
bra.uni BB1_41;

BB1_41:
setp.eq.s32	%p52, %r42, 7;
not.pred %p53, %p52;
mov.u32 %r401, %r38;
mov.u32 %r402, %r39;
mov.u32 %r403, %r40;
mov.u64 %rd370, %rd7;
mov.u64 %rd371, %rd8;
mov.u32 %r404, %r41;
@%p53 bra BB1_48;
bra.uni BB1_42;

BB1_42:
ld.f32 %f64, [%SP+384];
ld.f32 %f65, [%SP+388];
ld.f32 %f66, [%SP+392];
ld.f32 %f67, [%SP+396];

	st.shared.v4.f32 [%r38], {%f64, %f65, %f66, %f67};


	mov.u32 %r274, 0;
mov.u32 %r400, %r274;

BB1_43:
mov.u32 %r43, %r400;
setp.lt.s32	%p54, %r43, 4;
not.pred %p55, %p54;
@%p55 bra BB1_46;
bra.uni BB1_44;

BB1_44:
cvt.s64.s32	%rd330, %r43;
shl.b64 %rd331, %rd330, 2;
add.u64 %rd332, %SP, 400;
add.s64 %rd333, %rd332, %rd331;
cvt.u64.u32	%rd334, %r41;
mul.lo.s32 %r342, %r43, 32;
cvt.s64.s32	%rd335, %r342;
mul.lo.s64 %rd336, %rd335, 4;
add.s64 %rd337, %rd334, %rd336;
cvt.u32.u64	%r341, %rd337;
ld.f32 %f91, [%rd333];

	st.shared.f32 [%r341], %f91;



add.s32 %r44, %r43, 1;
mov.u32 %r400, %r44;
bra.uni BB1_43;

BB1_46:
bar.sync 0;

xor.b32 %r45, %r39, 8192;
xor.b32 %r46, %r40, 4096;
xor.b32 %r47, %r38, 8192;
xor.b32 %r48, %r41, 4096;
add.s64 %rd9, %rd7, 32;
cvt.u64.u32	%rd229, %r94;
add.s64 %rd10, %rd8, %rd229;
mov.u32 %r401, %r47;
mov.u32 %r402, %r45;
mov.u32 %r403, %r46;
mov.u64 %rd370, %rd9;
mov.u64 %rd371, %rd10;
mov.u32 %r404, %r48;

BB1_48:
mov.u32 %r52, %r404;
mov.u64 %rd12, %rd371;
mov.u64 %rd11, %rd370;
mov.u32 %r51, %r403;
mov.u32 %r50, %r402;
mov.u32 %r49, %r401;
add.s32 %r279, %r42, 1;
rem.s32 %r280, %r279, 2;
cvt.s64.s32	%rd230, %r280;
shl.b64 %rd231, %rd230, 5;
add.u64 %rd232, %SP, 0;
add.s64 %rd233, %rd232, %rd231;
add.s32 %r281, %r42, 1;
rem.s32 %r282, %r281, 2;
cvt.s64.s32	%rd234, %r282;
shl.b64 %rd235, %rd234, 5;
add.s64 %rd236, %rd232, %rd235;
add.s32 %r283, %r42, 1;
rem.s32 %r284, %r283, 2;
cvt.s64.s32	%rd237, %r284;
shl.b64 %rd238, %rd237, 5;
add.s64 %rd239, %rd232, %rd238;
add.s32 %r285, %r42, 1;
rem.s32 %r286, %r285, 2;
cvt.s64.s32	%rd240, %r286;
shl.b64 %rd241, %rd240, 5;
add.s64 %rd242, %rd232, %rd241;
cvt.u64.u32	%rd243, %r50;
add.s32 %r287, %r42, 1;
rem.s32 %r288, %r287, 8;
mul.lo.s32 %r289, %r288, 132;
cvt.s64.s32	%rd244, %r289;
mul.lo.s64 %rd245, %rd244, 4;
add.s64 %rd246, %rd243, %rd245;
cvt.u32.u64	%r275, %rd246;

	ld.shared.v4.f32 {%f68, %f69, %f70, %f71}, [%r275];


	st.f32 [%rd233], %f68;
st.f32 [%rd236+4], %f69;
st.f32 [%rd239+8], %f70;
st.f32 [%rd242+12], %f71;
add.s32 %r290, %r42, 1;
rem.s32 %r291, %r290, 2;
cvt.s64.s32	%rd247, %r291;
shl.b64 %rd248, %rd247, 5;
add.s64 %rd249, %rd232, %rd248;
add.s32 %r292, %r42, 1;
rem.s32 %r293, %r292, 2;
cvt.s64.s32	%rd250, %r293;
shl.b64 %rd251, %rd250, 5;
add.s64 %rd252, %rd232, %rd251;
add.s32 %r294, %r42, 1;
rem.s32 %r295, %r294, 2;
cvt.s64.s32	%rd253, %r295;
shl.b64 %rd254, %rd253, 5;
add.s64 %rd255, %rd232, %rd254;
add.s32 %r296, %r42, 1;
rem.s32 %r297, %r296, 2;
cvt.s64.s32	%rd256, %r297;
shl.b64 %rd257, %rd256, 5;
add.s64 %rd258, %rd232, %rd257;
cvt.u64.u32	%rd259, %r50;
add.s32 %r298, %r42, 1;
rem.s32 %r299, %r298, 8;
mul.lo.s32 %r300, %r299, 132;
add.s32 %r301, %r300, 16;
cvt.s64.s32	%rd260, %r301;
mul.lo.s64 %rd261, %rd260, 4;
add.s64 %rd262, %rd259, %rd261;
cvt.u32.u64	%r276, %rd262;

	ld.shared.v4.f32 {%f72, %f73, %f74, %f75}, [%r276];


	st.f32 [%rd249+16], %f72;
st.f32 [%rd252+20], %f73;
st.f32 [%rd255+24], %f74;
st.f32 [%rd258+28], %f75;
add.s32 %r302, %r42, 1;
rem.s32 %r303, %r302, 2;
cvt.s64.s32	%rd263, %r303;
shl.b64 %rd264, %rd263, 5;
add.u64 %rd265, %SP, 64;
add.s64 %rd266, %rd265, %rd264;
add.s32 %r304, %r42, 1;
rem.s32 %r305, %r304, 2;
cvt.s64.s32	%rd267, %r305;
shl.b64 %rd268, %rd267, 5;
add.s64 %rd269, %rd265, %rd268;
add.s32 %r306, %r42, 1;
rem.s32 %r307, %r306, 2;
cvt.s64.s32	%rd270, %r307;
shl.b64 %rd271, %rd270, 5;
add.s64 %rd272, %rd265, %rd271;
add.s32 %r308, %r42, 1;
rem.s32 %r309, %r308, 2;
cvt.s64.s32	%rd273, %r309;
shl.b64 %rd274, %rd273, 5;
add.s64 %rd275, %rd265, %rd274;
cvt.u64.u32	%rd276, %r51;
add.s32 %r310, %r42, 1;
rem.s32 %r311, %r310, 8;
mul.lo.s32 %r312, %r311, 128;
cvt.s64.s32	%rd277, %r312;
mul.lo.s64 %rd278, %rd277, 4;
add.s64 %rd279, %rd276, %rd278;
cvt.u32.u64	%r277, %rd279;

	ld.shared.v4.f32 {%f76, %f77, %f78, %f79}, [%r277];


	st.f32 [%rd266], %f76;
st.f32 [%rd269+4], %f77;
st.f32 [%rd272+8], %f78;
st.f32 [%rd275+12], %f79;
add.s32 %r313, %r42, 1;
rem.s32 %r314, %r313, 2;
cvt.s64.s32	%rd280, %r314;
shl.b64 %rd281, %rd280, 5;
add.s64 %rd282, %rd265, %rd281;
add.s32 %r315, %r42, 1;
rem.s32 %r316, %r315, 2;
cvt.s64.s32	%rd283, %r316;
shl.b64 %rd284, %rd283, 5;
add.s64 %rd285, %rd265, %rd284;
add.s32 %r317, %r42, 1;
rem.s32 %r318, %r317, 2;
cvt.s64.s32	%rd286, %r318;
shl.b64 %rd287, %rd286, 5;
add.s64 %rd288, %rd265, %rd287;
add.s32 %r319, %r42, 1;
rem.s32 %r320, %r319, 2;
cvt.s64.s32	%rd289, %r320;
shl.b64 %rd290, %rd289, 5;
add.s64 %rd291, %rd265, %rd290;
cvt.u64.u32	%rd292, %r51;
add.s32 %r321, %r42, 1;
rem.s32 %r322, %r321, 8;
mul.lo.s32 %r323, %r322, 128;
add.s32 %r324, %r323, 32;
cvt.s64.s32	%rd293, %r324;
mul.lo.s64 %rd294, %rd293, 4;
add.s64 %rd295, %rd292, %rd294;
cvt.u32.u64	%r278, %rd295;

	ld.shared.v4.f32 {%f80, %f81, %f82, %f83}, [%r278];


	st.f32 [%rd282+16], %f80;
st.f32 [%rd285+20], %f81;
st.f32 [%rd288+24], %f82;
st.f32 [%rd291+28], %f83;
setp.eq.s32	%p56, %r42, 0;
not.pred %p57, %p56;
@%p57 bra BB1_58;
bra.uni BB1_49;

BB1_49:
mov.u32 %r325, 0;
mov.u32 %r405, %r325;

BB1_50:
mov.u32 %r53, %r405;
setp.lt.s32	%p58, %r53, 4;
not.pred %p59, %p58;
@%p59 bra BB1_53;
bra.uni BB1_51;

BB1_51:
cvt.s64.s32	%rd325, %r53;
shl.b64 %rd326, %rd325, 2;
add.u64 %rd327, %SP, 384;
add.s64 %rd328, %rd327, %rd326;
mul.lo.s32 %r337, %r53, %r93;
cvt.u64.u32	%rd329, %r337;
add.s64 %rd324, %rd11, %rd329;
mov.u32 %r338, 1;
shl.b32 %r339, %r338, %r53;
and.b32 %r340, %r13, %r339;
setp.ne.s32	%p67, %r340, 0;
selp.u32	%r336, 1, 0, %p67;

	{.reg .pred p;
setp.ne.b32 p, %r336, 0;
@p ld.global.nc.f32 %f90, [%rd324];}


	st.f32 [%rd328], %f90;

add.s32 %r54, %r53, 1;
mov.u32 %r405, %r54;
bra.uni BB1_50;

BB1_53:
mov.u32 %r326, 0;
mov.u32 %r406, %r326;

BB1_54:
mov.u32 %r55, %r406;
setp.lt.s32	%p60, %r55, 4;
not.pred %p61, %p60;
@%p61 bra BB1_57;
bra.uni BB1_55;

BB1_55:
cvt.s64.s32	%rd318, %r55;
shl.b64 %rd319, %rd318, 2;
add.u64 %rd320, %SP, 400;
add.s64 %rd321, %rd320, %rd319;
mul.lo.s32 %r332, %r55, 32;
cvt.s64.s32	%rd322, %r332;
mul.lo.s64 %rd323, %rd322, 4;
add.s64 %rd317, %rd12, %rd323;
mov.u32 %r333, 1;
shl.b32 %r334, %r333, %r55;
and.b32 %r335, %r18, %r334;
setp.ne.s32	%p66, %r335, 0;
selp.u32	%r331, 1, 0, %p66;

	{.reg .pred p;
setp.ne.b32 p, %r331, 0;
@p ld.global.nc.f32 %f89, [%rd317];}


	st.f32 [%rd321], %f89;

add.s32 %r56, %r55, 1;
mov.u32 %r406, %r56;
bra.uni BB1_54;

BB1_57:

BB1_58:
mov.u32 %r327, 0;
mov.u32 %r407, %r327;

BB1_59:
mov.u32 %r57, %r407;
setp.lt.s32	%p62, %r57, 8;
not.pred %p63, %p62;
@%p63 bra BB1_66;
bra.uni BB1_60;

BB1_60:
mov.u32 %r328, 0;
mov.u32 %r408, %r328;

BB1_61:
mov.u32 %r58, %r408;
setp.lt.s32	%p64, %r58, 8;
not.pred %p65, %p64;
@%p65 bra BB1_64;
bra.uni BB1_62;

BB1_62:
rem.s32 %r329, %r42, 2;
cvt.s64.s32	%rd296, %r329;
shl.b64 %rd297, %rd296, 5;
add.u64 %rd298, %SP, 0;
add.s64 %rd299, %rd298, %rd297;
cvt.s64.s32	%rd300, %r57;
shl.b64 %rd301, %rd300, 2;
add.s64 %rd302, %rd299, %rd301;
ld.f32 %f84, [%rd302];
rem.s32 %r330, %r42, 2;
cvt.s64.s32	%rd303, %r330;
shl.b64 %rd304, %rd303, 5;
add.u64 %rd305, %SP, 64;
add.s64 %rd306, %rd305, %rd304;
cvt.s64.s32	%rd307, %r58;
shl.b64 %rd308, %rd307, 2;
add.s64 %rd309, %rd306, %rd308;
ld.f32 %f85, [%rd309];
mul.f32 %f86, %f84, %f85;
cvt.s64.s32	%rd310, %r57;
shl.b64 %rd311, %rd310, 5;
add.u64 %rd312, %SP, 128;
add.s64 %rd313, %rd312, %rd311;
cvt.s64.s32	%rd314, %r58;
shl.b64 %rd315, %rd314, 2;
add.s64 %rd316, %rd313, %rd315;
ld.f32 %f87, [%rd316];
add.f32 %f88, %f87, %f86;
st.f32 [%rd316], %f88;

add.s32 %r59, %r58, 1;
mov.u32 %r408, %r59;
bra.uni BB1_61;

BB1_64:

add.s32 %r60, %r57, 1;
mov.u32 %r407, %r60;
bra.uni BB1_59;

BB1_66:

add.s32 %r61, %r42, 1;
mov.u32 %r395, %r49;
mov.u32 %r396, %r50;
mov.u32 %r397, %r51;
mov.u64 %rd368, %rd11;
mov.u64 %rd369, %rd12;
mov.u32 %r398, %r52;
mov.u32 %r399, %r61;
bra.uni BB1_40;

BB1_68:

add.s32 %r62, %r37, -1;
mov.u32 %r390, %r38;
mov.u32 %r391, %r39;
mov.u32 %r392, %r40;
mov.u64 %rd366, %rd7;
mov.u64 %rd367, %rd8;
mov.u32 %r393, %r41;
mov.u32 %r394, %r62;
bra.uni BB1_38;

BB1_70:
mov.u32 %r156, 0;
mov.u32 %r409, %r156;

BB1_71:
mov.u32 %r63, %r409;
setp.lt.s32	%p19, %r63, 8;
not.pred %p20, %p19;
@%p20 bra BB1_84;
bra.uni BB1_72;

BB1_72:
setp.lt.s32	%p44, %r63, 7;
not.pred %p45, %p44;
@%p45 bra BB1_74;
bra.uni BB1_73;

BB1_73:
add.s32 %r222, %r63, 1;
rem.s32 %r223, %r222, 2;
cvt.s64.s32	%rd142, %r223;
shl.b64 %rd143, %rd142, 5;
add.u64 %rd144, %SP, 0;
add.s64 %rd145, %rd144, %rd143;
add.s32 %r224, %r63, 1;
rem.s32 %r225, %r224, 2;
cvt.s64.s32	%rd146, %r225;
shl.b64 %rd147, %rd146, 5;
add.s64 %rd148, %rd144, %rd147;
add.s32 %r226, %r63, 1;
rem.s32 %r227, %r226, 2;
cvt.s64.s32	%rd149, %r227;
shl.b64 %rd150, %rd149, 5;
add.s64 %rd151, %rd144, %rd150;
add.s32 %r228, %r63, 1;
rem.s32 %r229, %r228, 2;
cvt.s64.s32	%rd152, %r229;
shl.b64 %rd153, %rd152, 5;
add.s64 %rd154, %rd144, %rd153;
cvt.u64.u32	%rd155, %r34;
add.s32 %r230, %r63, 1;
rem.s32 %r231, %r230, 8;
mul.lo.s32 %r232, %r231, 132;
cvt.s64.s32	%rd156, %r232;
mul.lo.s64 %rd157, %rd156, 4;
add.s64 %rd158, %rd155, %rd157;
cvt.u32.u64	%r218, %rd158;

	ld.shared.v4.f32 {%f43, %f44, %f45, %f46}, [%r218];


	st.f32 [%rd145], %f43;
st.f32 [%rd148+4], %f44;
st.f32 [%rd151+8], %f45;
st.f32 [%rd154+12], %f46;
add.s32 %r233, %r63, 1;
rem.s32 %r234, %r233, 2;
cvt.s64.s32	%rd159, %r234;
shl.b64 %rd160, %rd159, 5;
add.s64 %rd161, %rd144, %rd160;
add.s32 %r235, %r63, 1;
rem.s32 %r236, %r235, 2;
cvt.s64.s32	%rd162, %r236;
shl.b64 %rd163, %rd162, 5;
add.s64 %rd164, %rd144, %rd163;
add.s32 %r237, %r63, 1;
rem.s32 %r238, %r237, 2;
cvt.s64.s32	%rd165, %r238;
shl.b64 %rd166, %rd165, 5;
add.s64 %rd167, %rd144, %rd166;
add.s32 %r239, %r63, 1;
rem.s32 %r240, %r239, 2;
cvt.s64.s32	%rd168, %r240;
shl.b64 %rd169, %rd168, 5;
add.s64 %rd170, %rd144, %rd169;
cvt.u64.u32	%rd171, %r34;
add.s32 %r241, %r63, 1;
rem.s32 %r242, %r241, 8;
mul.lo.s32 %r243, %r242, 132;
add.s32 %r244, %r243, 16;
cvt.s64.s32	%rd172, %r244;
mul.lo.s64 %rd173, %rd172, 4;
add.s64 %rd174, %rd171, %rd173;
cvt.u32.u64	%r219, %rd174;

	ld.shared.v4.f32 {%f47, %f48, %f49, %f50}, [%r219];


	st.f32 [%rd161+16], %f47;
st.f32 [%rd164+20], %f48;
st.f32 [%rd167+24], %f49;
st.f32 [%rd170+28], %f50;
add.s32 %r245, %r63, 1;
rem.s32 %r246, %r245, 2;
cvt.s64.s32	%rd175, %r246;
shl.b64 %rd176, %rd175, 5;
add.u64 %rd177, %SP, 64;
add.s64 %rd178, %rd177, %rd176;
add.s32 %r247, %r63, 1;
rem.s32 %r248, %r247, 2;
cvt.s64.s32	%rd179, %r248;
shl.b64 %rd180, %rd179, 5;
add.s64 %rd181, %rd177, %rd180;
add.s32 %r249, %r63, 1;
rem.s32 %r250, %r249, 2;
cvt.s64.s32	%rd182, %r250;
shl.b64 %rd183, %rd182, 5;
add.s64 %rd184, %rd177, %rd183;
add.s32 %r251, %r63, 1;
rem.s32 %r252, %r251, 2;
cvt.s64.s32	%rd185, %r252;
shl.b64 %rd186, %rd185, 5;
add.s64 %rd187, %rd177, %rd186;
cvt.u64.u32	%rd188, %r35;
add.s32 %r253, %r63, 1;
rem.s32 %r254, %r253, 8;
mul.lo.s32 %r255, %r254, 128;
cvt.s64.s32	%rd189, %r255;
mul.lo.s64 %rd190, %rd189, 4;
add.s64 %rd191, %rd188, %rd190;
cvt.u32.u64	%r220, %rd191;

	ld.shared.v4.f32 {%f51, %f52, %f53, %f54}, [%r220];


	st.f32 [%rd178], %f51;
st.f32 [%rd181+4], %f52;
st.f32 [%rd184+8], %f53;
st.f32 [%rd187+12], %f54;
add.s32 %r256, %r63, 1;
rem.s32 %r257, %r256, 2;
cvt.s64.s32	%rd192, %r257;
shl.b64 %rd193, %rd192, 5;
add.s64 %rd194, %rd177, %rd193;
add.s32 %r258, %r63, 1;
rem.s32 %r259, %r258, 2;
cvt.s64.s32	%rd195, %r259;
shl.b64 %rd196, %rd195, 5;
add.s64 %rd197, %rd177, %rd196;
add.s32 %r260, %r63, 1;
rem.s32 %r261, %r260, 2;
cvt.s64.s32	%rd198, %r261;
shl.b64 %rd199, %rd198, 5;
add.s64 %rd200, %rd177, %rd199;
add.s32 %r262, %r63, 1;
rem.s32 %r263, %r262, 2;
cvt.s64.s32	%rd201, %r263;
shl.b64 %rd202, %rd201, 5;
add.s64 %rd203, %rd177, %rd202;
cvt.u64.u32	%rd204, %r35;
add.s32 %r264, %r63, 1;
rem.s32 %r265, %r264, 8;
mul.lo.s32 %r266, %r265, 128;
add.s32 %r267, %r266, 32;
cvt.s64.s32	%rd205, %r267;
mul.lo.s64 %rd206, %rd205, 4;
add.s64 %rd207, %rd204, %rd206;
cvt.u32.u64	%r221, %rd207;

	ld.shared.v4.f32 {%f55, %f56, %f57, %f58}, [%r221];


	st.f32 [%rd194+16], %f55;
st.f32 [%rd197+20], %f56;
st.f32 [%rd200+24], %f57;
st.f32 [%rd203+28], %f58;

BB1_74:
mov.u32 %r268, 0;
mov.u32 %r410, %r268;

BB1_75:
mov.u32 %r64, %r410;
setp.lt.s32	%p46, %r64, 8;
not.pred %p47, %p46;
@%p47 bra BB1_82;
bra.uni BB1_76;

BB1_76:
mov.u32 %r269, 0;
mov.u32 %r411, %r269;

BB1_77:
mov.u32 %r65, %r411;
setp.lt.s32	%p48, %r65, 8;
not.pred %p49, %p48;
@%p49 bra BB1_80;
bra.uni BB1_78;

BB1_78:
rem.s32 %r270, %r63, 2;
cvt.s64.s32	%rd208, %r270;
shl.b64 %rd209, %rd208, 5;
add.u64 %rd210, %SP, 0;
add.s64 %rd211, %rd210, %rd209;
cvt.s64.s32	%rd212, %r64;
shl.b64 %rd213, %rd212, 2;
add.s64 %rd214, %rd211, %rd213;
ld.f32 %f59, [%rd214];
rem.s32 %r271, %r63, 2;
cvt.s64.s32	%rd215, %r271;
shl.b64 %rd216, %rd215, 5;
add.u64 %rd217, %SP, 64;
add.s64 %rd218, %rd217, %rd216;
cvt.s64.s32	%rd219, %r65;
shl.b64 %rd220, %rd219, 2;
add.s64 %rd221, %rd218, %rd220;
ld.f32 %f60, [%rd221];
mul.f32 %f61, %f59, %f60;
cvt.s64.s32	%rd222, %r64;
shl.b64 %rd223, %rd222, 5;
add.u64 %rd224, %SP, 128;
add.s64 %rd225, %rd224, %rd223;
cvt.s64.s32	%rd226, %r65;
shl.b64 %rd227, %rd226, 2;
add.s64 %rd228, %rd225, %rd227;
ld.f32 %f62, [%rd228];
add.f32 %f63, %f62, %f61;
st.f32 [%rd228], %f63;

add.s32 %r66, %r65, 1;
mov.u32 %r411, %r66;
bra.uni BB1_77;

BB1_80:

add.s32 %r67, %r64, 1;
mov.u32 %r410, %r67;
bra.uni BB1_75;

BB1_82:

add.s32 %r68, %r63, 1;
mov.u32 %r409, %r68;
bra.uni BB1_71;

BB1_84:
mul.lo.s32 %r158, %r6, 2048;
cvt.u64.u32	%rd67, %r158;
mov.u32 %r159, _ZZ22sgemm_128x128x8_kernelPKfS0_PfjjjjjE4smem;
{
.reg .u64 %temp; 
cvt.u64.u32 %temp, %r159;
cvta.shared.u64 %rd68, %temp;
}
add.s64 %rd69, %rd68, %rd67;
mul.lo.s32 %r160, %r8, 4;
mul.lo.s32 %r161, %r160, 8;
cvt.u64.u32	%rd70, %r161;
shl.b64 %rd71, %rd70, 4;
add.s64 %rd72, %rd69, %rd71;
cvt.u64.u32	%rd73, %r7;
shl.b64 %rd74, %rd73, 4;
add.s64 %rd66, %rd72, %rd74;

	{.reg .u64 u64addr;
cvta.to.shared.u64 u64addr, %rd66;
cvt.u32.u64 %r157, u64addr;}


	mul.lo.s32 %r162, %r6, 2048;
cvt.u64.u32	%rd75, %r162;
add.s64 %rd76, %rd68, %rd75;
cvt.u64.u32	%rd77, %r5;
shl.b64 %rd78, %rd77, 2;
add.s64 %rd13, %rd76, %rd78;
mov.u32 %r163, %ctaid.y;
mul.lo.s32 %r164, %r163, 128;
div.u32 %r165, %r6, 2;
mul.lo.s32 %r166, %r165, 32;
add.s32 %r70, %r164, %r166;
mov.u32 %r167, %ctaid.x;
mul.lo.s32 %r168, %r167, 128;
rem.u32 %r169, %r6, 2;
mul.lo.s32 %r170, %r169, 64;
add.s32 %r171, %r168, %r170;
add.s32 %r71, %r171, %r5;
mul.lo.s32 %r172, %r70, %r91;
cvt.u64.u32	%rd79, %r172;
shl.b64 %rd80, %rd79, 2;
add.s64 %rd81, %rd17, %rd80;
cvt.u64.u32	%rd82, %r71;
shl.b64 %rd83, %rd82, 2;
add.s64 %rd14, %rd81, %rd83;
setp.ge.u32	%p21, %r70, %r90;
not.pred %p22, %p21;
@%p22 bra BB1_86;
bra.uni BB1_85;

BB1_85:
bra.uni BB1_124;

BB1_86:
add.s32 %r173, %r70, 32;
setp.le.u32	%p23, %r173, %r90;
not.pred %p24, %p23;
@%p24 bra BB1_107;
bra.uni BB1_87;

BB1_87:
setp.lt.u32	%p33, %r91, %r71;
not.pred %p34, %p33;
@%p34 bra BB1_89;
bra.uni BB1_88;

BB1_88:
mov.u32 %r189, 0;
mov.u32 %r412, %r189;
bra.uni BB1_90;

BB1_89:
sub.s32 %r72, %r91, %r71;
mov.u32 %r412, %r72;

BB1_90:
mov.u32 %r73, %r412;
mov.u32 %r190, 0;
mov.u32 %r413, %r190;

BB1_91:
mov.u32 %r74, %r413;
setp.lt.s32	%p35, %r74, 2;
not.pred %p36, %p35;
@%p36 bra BB1_106;
bra.uni BB1_92;

BB1_92:
mov.u32 %r191, 0;
mov.u32 %r414, %r191;

BB1_93:
mov.u32 %r75, %r414;
setp.lt.s32	%p37, %r75, 2;
not.pred %p38, %p37;
@%p38 bra BB1_104;
bra.uni BB1_94;

BB1_94:
bar.sync 0;
mov.u32 %r192, 0;
mov.u32 %r415, %r192;

BB1_95:
mov.u32 %r76, %r415;
setp.lt.s32	%p39, %r76, 4;
not.pred %p40, %p39;
@%p40 bra BB1_98;
bra.uni BB1_96;

BB1_96:
mul.lo.s32 %r202, %r74, 4;
add.s32 %r203, %r202, %r76;
cvt.s64.s32	%rd113, %r203;
shl.b64 %rd114, %rd113, 5;
add.u64 %rd115, %SP, 128;
add.s64 %rd116, %rd115, %rd114;
mul.lo.s32 %r204, %r75, 4;
cvt.s64.s32	%rd117, %r204;
shl.b64 %rd118, %rd117, 2;
add.s64 %rd119, %rd116, %rd118;
mul.lo.s32 %r205, %r74, 4;
add.s32 %r206, %r205, %r76;
cvt.s64.s32	%rd120, %r206;
shl.b64 %rd121, %rd120, 5;
add.s64 %rd122, %rd115, %rd121;
mul.lo.s32 %r207, %r75, 4;
add.s32 %r208, %r207, 1;
cvt.s64.s32	%rd123, %r208;
shl.b64 %rd124, %rd123, 2;
add.s64 %rd125, %rd122, %rd124;
mul.lo.s32 %r209, %r74, 4;
add.s32 %r210, %r209, %r76;
cvt.s64.s32	%rd126, %r210;
shl.b64 %rd127, %rd126, 5;
add.s64 %rd128, %rd115, %rd127;
mul.lo.s32 %r211, %r75, 4;
add.s32 %r212, %r211, 2;
cvt.s64.s32	%rd129, %r212;
shl.b64 %rd130, %rd129, 2;
add.s64 %rd131, %rd128, %rd130;
mul.lo.s32 %r213, %r74, 4;
add.s32 %r214, %r213, %r76;
cvt.s64.s32	%rd132, %r214;
shl.b64 %rd133, %rd132, 5;
add.s64 %rd134, %rd115, %rd133;
mul.lo.s32 %r215, %r75, 4;
add.s32 %r216, %r215, 3;
cvt.s64.s32	%rd135, %r216;
shl.b64 %rd136, %rd135, 2;
add.s64 %rd137, %rd134, %rd136;
cvt.u64.u32	%rd138, %r157;
mul.lo.s32 %r217, %r76, 8;
cvt.s64.s32	%rd139, %r217;
mul.lo.s64 %rd140, %rd139, 16;
add.s64 %rd141, %rd138, %rd140;
cvt.u32.u64	%r201, %rd141;
ld.f32 %f39, [%rd119];
ld.f32 %f40, [%rd125];
ld.f32 %f41, [%rd131];
ld.f32 %f42, [%rd137];

	st.shared.v4.f32 [%r201], {%f39, %f40, %f41, %f42};



add.s32 %r77, %r76, 1;
mov.u32 %r415, %r77;
bra.uni BB1_95;

BB1_98:
bar.sync 0;
mov.u32 %r193, 0;
mov.u32 %r416, %r193;

BB1_99:
mov.u32 %r78, %r416;
setp.lt.s32	%p41, %r78, 16;
not.pred %p42, %p41;
@%p42 bra BB1_102;
bra.uni BB1_100;

BB1_100:
mul.lo.s32 %r195, %r78, 32;
cvt.s64.s32	%rd105, %r195;
shl.b64 %rd106, %rd105, 2;
add.s64 %rd107, %rd13, %rd106;
mul.lo.s32 %r196, %r74, 16;
add.s32 %r197, %r196, %r78;
mul.lo.s32 %r198, %r197, %r91;
cvt.u64.u32	%rd108, %r198;
shl.b64 %rd109, %rd108, 2;
add.s64 %rd110, %rd14, %rd109;
mul.lo.s32 %r199, %r75, 32;
cvt.s64.s32	%rd111, %r199;
shl.b64 %rd112, %rd111, 2;
add.s64 %rd104, %rd110, %rd112;
mul.lo.s32 %r200, %r75, 32;
setp.lt.u32	%p43, %r200, %r73;
ld.f32 %f38, [%rd107];
selp.u32	%r194, 1, 0, %p43;

	{.reg .pred p;
setp.ne.b32 p, %r194, 0;
@p st.global.f32 [%rd104], %f38;}



add.s32 %r79, %r78, 1;
mov.u32 %r416, %r79;
bra.uni BB1_99;

BB1_102:

add.s32 %r80, %r75, 1;
mov.u32 %r414, %r80;
bra.uni BB1_93;

BB1_104:

add.s32 %r81, %r74, 1;
mov.u32 %r413, %r81;
bra.uni BB1_91;

BB1_106:
bra.uni BB1_122;

BB1_107:
mov.u32 %r174, 0;
mov.u32 %r417, %r174;

BB1_108:
mov.u32 %r82, %r417;
setp.lt.s32	%p25, %r82, 2;
not.pred %p26, %p25;
@%p26 bra BB1_121;
bra.uni BB1_109;

BB1_109:
mov.u32 %r175, 0;
mov.u32 %r418, %r175;

BB1_110:
mov.u32 %r83, %r418;
setp.lt.s32	%p27, %r83, 2;
not.pred %p28, %p27;
@%p28 bra BB1_119;
bra.uni BB1_111;

BB1_111:
mov.u32 %r176, 0;
mov.u32 %r419, %r176;

BB1_112:
mov.u32 %r84, %r419;
setp.lt.s32	%p29, %r84, 4;
not.pred %p30, %p29;
@%p30 bra BB1_117;
bra.uni BB1_113;

BB1_113:
mov.u32 %r184, 0;
mov.u32 %r420, %r184;

BB1_114:
mov.u32 %r85, %r420;
setp.lt.s32	%p31, %r85, 4;
not.pred %p32, %p31;
@%p32 bra BB1_116;
bra.uni BB1_115;

BB1_115:
mul.lo.s32 %r185, %r82, 4;
add.s32 %r186, %r185, %r84;
cvt.s64.s32	%rd90, %r186;
shl.b64 %rd91, %rd90, 5;
add.u64 %rd92, %SP, 128;
add.s64 %rd93, %rd92, %rd91;
mul.lo.s32 %r187, %r83, 4;
add.s32 %r188, %r187, %r85;
cvt.s64.s32	%rd94, %r188;
shl.b64 %rd95, %rd94, 2;
add.s64 %rd96, %rd93, %rd95;
ld.f32 %f37, [%rd96];
cvt.s64.s32	%rd97, %r84;
shl.b64 %rd98, %rd97, 4;
add.u64 %rd99, %SP, 416;
add.s64 %rd100, %rd99, %rd98;
cvt.s64.s32	%rd101, %r85;
shl.b64 %rd102, %rd101, 2;
add.s64 %rd103, %rd100, %rd102;
st.f32 [%rd103], %f37;
add.s32 %r86, %r85, 1;
mov.u32 %r420, %r86;
bra.uni BB1_114;

BB1_116:
add.s32 %r87, %r84, 1;
mov.u32 %r419, %r87;
bra.uni BB1_112;

BB1_117:
ld.f32 %f21, [%SP+476];
ld.f32 %f22, [%SP+472];
ld.f32 %f23, [%SP+468];
ld.f32 %f24, [%SP+464];
ld.f32 %f25, [%SP+460];
ld.f32 %f26, [%SP+456];
ld.f32 %f27, [%SP+452];
ld.f32 %f28, [%SP+448];
ld.f32 %f29, [%SP+444];
ld.f32 %f30, [%SP+440];
ld.f32 %f31, [%SP+436];
ld.f32 %f32, [%SP+432];
ld.f32 %f33, [%SP+428];
ld.f32 %f34, [%SP+424];
ld.f32 %f35, [%SP+420];
ld.f32 %f36, [%SP+416];
mul.lo.s32 %r177, %r82, 16;
mul.lo.s32 %r178, %r177, %r91;
cvt.u64.u32	%rd84, %r178;
shl.b64 %rd85, %rd84, 2;
add.s64 %rd86, %rd14, %rd85;
mul.lo.s32 %r179, %r83, 32;
cvt.s64.s32	%rd87, %r179;
shl.b64 %rd88, %rd87, 2;
add.s64 %rd89, %rd86, %rd88;
mul.lo.s32 %r180, %r82, 16;
add.s32 %r181, %r70, %r180;
mul.lo.s32 %r182, %r83, 32;
add.s32 %r183, %r71, %r182;

	{
.reg .b32 temp_param_reg;

	.param .align 4 .b8 param0[64];
st.param.f32	[param0+0], %f36;
st.param.f32	[param0+4], %f35;
st.param.f32	[param0+8], %f34;
st.param.f32	[param0+12], %f33;
st.param.f32	[param0+16], %f32;
st.param.f32	[param0+20], %f31;
st.param.f32	[param0+24], %f30;
st.param.f32	[param0+28], %f29;
st.param.f32	[param0+32], %f28;
st.param.f32	[param0+36], %f27;
st.param.f32	[param0+40], %f26;
st.param.f32	[param0+44], %f25;
st.param.f32	[param0+48], %f24;
st.param.f32	[param0+52], %f23;
st.param.f32	[param0+56], %f22;
st.param.f32	[param0+60], %f21;
.param .b64 param1;
st.param.b64	[param1+0], %rd89;
.param .b64 param2;
st.param.b64	[param2+0], %rd13;
.param .b32 param3;
st.param.b32	[param3+0], %r157;
.param .b32 param4;
st.param.b32	[param4+0], %r90;
.param .b32 param5;
st.param.b32	[param5+0], %r91;
.param .b32 param6;
st.param.b32	[param6+0], %r181;
.param .b32 param7;
st.param.b32	[param7+0], %r183;
call.uni 
_Z9C_tile_wb7StgFragPfPKfjjjjj, 
(
param0, 
param1, 
param2, 
param3, 
param4, 
param5, 
param6, 
param7
);


	}

add.s32 %r88, %r83, 1;
mov.u32 %r418, %r88;
bra.uni BB1_110;

BB1_119:

add.s32 %r89, %r82, 1;
mov.u32 %r417, %r89;
bra.uni BB1_108;

BB1_121:

BB1_122:


BB1_124:
ret;
}


